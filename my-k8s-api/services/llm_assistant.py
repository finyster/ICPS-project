# services/llm_assistant.py
from __future__ import annotations
import os, json, requests
from typing import List, Dict, Any
from dotenv import load_dotenv
from groq import Groq
from typing import Optional
from pydantic import BaseModel
import re
from datetime import datetime, timedelta
from services.rag_utils_en import rag_retrieve, is_supported

class ChatResponse(BaseModel):
    assistant: Optional[str]
    history: List[dict]

load_dotenv()

PROMETHEUS_URL = os.getenv("PROMETHEUS_URL", "http://localhost:9090")
GROQ_API_KEY   = os.getenv("GROQ_API_KEY")
MODEL          = "llama3-8b-8192"   # è«‹æ”¹æˆä½ å¸³è™Ÿå¯ç”¨çš„ Groq æ¨¡å‹åç¨±

if not GROQ_API_KEY:
    raise RuntimeError("âŒ GROQ_API_KEY æœªè¨­å®šï¼")

client = Groq(api_key=GROQ_API_KEY)

# ------------------------ Prometheus å°å·¥å…· ------------------------ #
def _prom_query(q: str) -> dict:
    try:
        r = requests.get(f"{PROMETHEUS_URL}/api/v1/query", params={"query": q}, timeout=10)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        return {"status": "error", "error": str(e)}

def _prom_query_range(q: str, start: str, end: str, step: str = "1h") -> dict:
    try:
        params = {
            "query": q,
            "start": start,
            "end": end,
            "step": step
        }
        r = requests.get(f"{PROMETHEUS_URL}/api/v1/query_range", params=params, timeout=10)
        r.raise_for_status()
        return r.json()
    except Exception as e:
        return {"status": "error", "error": str(e)}

def get_pod_cpu_usage(namespace: str, pod: str, range_str: str = "[1h]",**kwargs) -> str:
    q = f'container_cpu_usage_seconds_total{{namespace="{namespace}",pod="{pod}"}}{range_str}'
    return json.dumps(_prom_query(q))

def get_pod_memory_usage(namespace: str, pod: str, range_str: str = "[1h]", **kwargs) -> str:
    q = f'container_memory_usage_bytes{{namespace="{namespace}",pod="{pod}"}}{range_str}'
    return json.dumps(_prom_query(q))

def get_top_cpu_pods(namespace: str, k: int = 3, **kwargs) -> str:
    q = f'topk({k}, sum by(pod)(rate(container_cpu_usage_seconds_total{{namespace="{namespace}"}}[5m])))'
    print(f"[DEBUG] get_top_cpu_pods called with namespace={namespace}, k={k}, extra={kwargs}")
    return json.dumps(_prom_query(q))

def get_top_memory_pods(namespace: str, k: int = 3, **kwargs) -> str:
    q = f'topk({k}, sum by(pod)(container_memory_usage_bytes{{namespace="{namespace}"}}))'
    print(f"[DEBUG] get_top_cpu_pods called with namespace={namespace}, k={k}, extra={kwargs}")
    return json.dumps(_prom_query(q))

def get_pod_resource_usage_over_time(namespace: str, pod: str, days: int = 7) -> str:
    """Get CPU and memory usage for a pod over a period of days"""
    end = "now()"
    start = f"now()-{days}d"
    
    cpu_query = f'container_cpu_usage_seconds_total{{namespace="{namespace}",pod="{pod}"}}'
    mem_query = f'container_memory_usage_bytes{{namespace="{namespace}",pod="{pod}"}}'
    
    cpu_data = _prom_query_range(cpu_query, start, end, "1h")
    mem_data = _prom_query_range(mem_query, start, end, "1h")
    
    return json.dumps({
        "cpu_usage": cpu_data,
        "memory_usage": mem_data
    })

def get_namespace_resource_usage_over_time(namespace: str, days: int = 7, **kwargs) -> str:
    """Get resource usage for all pods in a namespace over time"""
    end = "now()"
    start = f"now()-{days}d"
    
    cpu_query = f'sum by(pod)(rate(container_cpu_usage_seconds_total{{namespace="{namespace}"}}[5m]))'
    mem_query = f'sum by(pod)(container_memory_usage_bytes{{namespace="{namespace}"}})'
    
    cpu_data = _prom_query_range(cpu_query, start, end, "1h")
    mem_data = _prom_query_range(mem_query, start, end, "1h")
    
    return json.dumps({
        "cpu_usage": cpu_data,
        "memory_usage": mem_data
    })
'''
æ–°çš„å…©éš»å·¥å…·
'''
def query_resource(level: str, target: str, metric: str, duration: str, namespace: str | None = None) -> str:
    """
    æŸ¥è©¢ pod / node / namespace çš„ CPU æˆ–è¨˜æ†¶é«”ä½¿ç”¨é‡ï¼Œæ”¯æ´ç¯„åœæ™‚é–“é©—è­‰ã€‚
    æ”¯æ´æ ¼å¼ï¼š30m, 1h, 2d, 1moï¼ˆæœ€å¤š 10moï¼‰
    """

    # é©—è­‰ duration æ ¼å¼
    match = re.match(r"^(\d+)(m|h|d|mo)$", duration)
    if not match:
        return json.dumps({"error": "Invalid duration format. Use 30m, 1h, 2d, 1mo"})

    value, unit = match.groups()
    value = int(value)
    if unit == "mo" and value > 10:
        return json.dumps({"error": "Max supported duration is 10mo"})

    now = datetime.utcnow()
    delta = {
        "mo": timedelta(days=30 * value),
        "d": timedelta(days=value),
        "h": timedelta(hours=value),
        "m": timedelta(minutes=value),
    }.get(unit)

    if not delta:
        return json.dumps({"error": "Unsupported time unit"})

    start = int((now - delta).timestamp())
    end = int(now.timestamp())
    step = "1h"

    # æ¸…ç† metric æ ¼å¼ï¼šè™•ç† "cpu.usage" or "memory.usage"
    metric = metric.lower().replace(".usage", "")
    if metric not in ("cpu", "memory"):
        return json.dumps({"error": "Metric must be 'cpu' or 'memory'"})

    # å»ºç«‹ Prometheus æŸ¥è©¢
    if level == "pod":
        if not namespace:
            return json.dumps({"error": "Namespace is required for pod-level query"})
        query = f'container_{metric}_usage_seconds_total{{namespace="{namespace}",pod="{target}"}}'
    elif level == "node":
        query = f'node_{metric}_usage_seconds_total{{node="{target}"}}'
    elif level == "namespace":
        query = f'container_{metric}_usage_seconds_total{{namespace="{target}"}}'
    else:
        return json.dumps({"error": f"Unsupported level: {level}"})

    result = _prom_query_range(query, start, end, step)
    return json.dumps(result)

def top_k_pods(namespace: str, metric: str, k: int = 3, duration: str = "5m") -> str:
    """
    å›å‚³æŸ namespace å…§ï¼ŒCPU æˆ–è¨˜æ†¶é«”ä½¿ç”¨æœ€é«˜çš„å‰ K å€‹ podã€‚
    """
    if metric not in ("cpu", "memory"):
        return json.dumps({"error": "Invalid metric. Use 'cpu' or 'memory'"})

    if metric == "cpu":
        query = f'topk({k}, sum by(pod)(rate(container_cpu_usage_seconds_total{{namespace="{namespace}"}}[{duration}])))'
    else:
        query = f'topk({k}, sum by(pod)(container_memory_usage_bytes{{namespace="{namespace}"}}))'

    return json.dumps(_prom_query(query))

# â”€â”€â”€â”€ CSV ä¸‹è¼‰é€£çµ â”€â”€â”€â”€
# é€™é‚Šåªæ˜¯å›å‚³ä¸€å€‹ä¸‹è¼‰é€£çµï¼Œå¯¦éš›çš„ CSV ç”Ÿæˆåœ¨ export_csv.py è£¡é¢
def generate_csv_link(namespace: str, pod: str, range: str = "[1h]") -> str:
    if not range.startswith("["):
        bracketed = f"[{range}]"
    else:
        bracketed = range
    url = f"/api/export_csv?namespace={namespace}&pod={pod}&range={bracketed}"
    return json.dumps({
        "message": f"You can download the CSV from: [Download CSV]({url})"
    })

TOOLS_DEF: List[dict] = [
    {
        "type": "function",
        "function": {
            "name": "get_pod_cpu_usage",
            "description": "Get CPU usage for a specific pod in a namespace",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": {"type": "string"},
                    "pod": {"type": "string"},
                    "range_str": {"type": "string", "default": "[1h]"},
                },
                "required": ["namespace", "pod"]
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_pod_memory_usage",
            "description": "Get memory usage for a specific pod in a namespace",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": {"type": "string"},
                    "pod": {"type": "string"},
                    "range_str": {"type": "string", "default": "[1h]"},
                },
                "required": ["namespace", "pod"]
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_top_cpu_pods",
            "description": "Topâ€‘K pods by CPU usage in a namespace",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": {"type": "string"},
                    "k": {"type": "integer", "default": 3},
                },
                "required": ["namespace"]
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_top_memory_pods",
            "description": "Topâ€‘K pods by memory usage in a namespace",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": {"type": "string"},
                    "k": {"type": "integer", "default": 3},
                },
                "required": ["namespace"]
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_pod_resource_usage_over_time",
            "description": "Get CPU and memory usage for a pod over the past N days",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": {"type": "string"},
                    "pod":       {"type": "string"},
                    "days":      {"type": "integer"}
                },
                "required": ["namespace","pod","days"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_namespace_resource_usage_over_time",
            "description": "Get resource usage for all pods in a namespace over time",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": {"type": "string"},
                    "days": {"type": "integer", "default": 7},
                },
                "required": ["namespace"]
            },
        },
    },
    {
        "type": "function",           # ğŸ‘ˆ åŠ é€™è¡Œ
        "function": {
            "name": "get_pod_resource_usage_over_time",
            "description": "Get CPU and memory usage for a pod over the past N days",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": {"type": "string"},
                    "pod":       {"type": "string"},
                    "days":      {"type": "integer"}
                },
                "required": ["namespace", "pod", "days"]
            }
        }
    },


    {
        "type": "function",
        "function": {
            "name": "query_resource",
            "description": "Query CPU or Memory usage for pod / node / namespace.",
            "parameters": {
                "type": "object",
                "properties": {
                "level":   { "type": "string", "enum": ["pod", "node", "namespace"] },
                "target":  { "type": "string", "description": "pod name, node name, or namespace name" },
                "metric":  { "type": "string", "enum": ["cpu", "memory"] },
                "duration": { "type": "string", "description": "lookâ€‘back window like 30m, 4h, 2d, 1mo (max 10mo)" },
                "namespace":{ "type": "string" }           # â† **æ³¨æ„ï¼šå‰é¢è¦æœ‰é€—è™Ÿ**
                },
                "required": ["level","target","metric","duration"]
            }
        }
    },
    # åªæˆªå– top_k_pods çš„å®šç¾©éƒ¨åˆ†
    {
        "type": "function",
        "function": {
            "name": "top_k_pods",
            "description": "Return topâ€‘K pods by CPU/Memory in a namespace",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": { "type": "string",
                                "description": "Kubernetes namespace" },
                    "metric":    { "type": "string",
                                "enum": ["cpu", "memory"] },
                    "k":         { "type": "integer",
                                "default": 3,
                                "minimum": 1,
                                "description": "How many pods to return" },
                    "duration":  { "type": "string",
                                "default": "5m",
                                "pattern": "^(\\d+)(m|h|d|mo)$",
                                "description": "Lookâ€‘back window like 30m, 2h, 1d" }
                },
                "required": ["namespace", "metric"]
            }
        }
    },
    # â”€â”€â”€ csv generator â”€â”€â”€
    {
        "type": "function",
        "function": {
            "name": "generate_csv_link",
            "description": "Generate a CSV download link for a specific pod's CPU/Memory usage",
            "parameters": {
                "type": "object",
                "properties": {
                    "namespace": { "type": "string" },
                    "pod":       { "type": "string" },
                    "range":     { "type": "string", "default": "1h" }
                },
                "required": ["namespace", "pod"]
            }
        }
    }

]

FUNC_MAP = {
    "get_pod_cpu_usage": get_pod_cpu_usage,
    "get_pod_memory_usage": get_pod_memory_usage,
    "get_top_cpu_pods": get_top_cpu_pods,
    "get_top_memory_pods": get_top_memory_pods,
    "get_pod_resource_usage_over_time": get_pod_resource_usage_over_time,
    "get_namespace_resource_usage_over_time": get_namespace_resource_usage_over_time,
     # â”€â”€â”€ æ–° 2 æ”¯ â”€â”€â”€
    "query_resource": query_resource,
    "top_k_pods":     top_k_pods,
    # â”€â”€â”€ CSV ä¸‹è¼‰ â”€â”€â”€
    "generate_csv_link": generate_csv_link,
}
SYSTEM_PROMPT = """
You are a Kubernetes observability assistant. Your job is to help users monitor, analyze, and troubleshoot cluster resources in real-time.

Your capabilities include:
1. Monitoring CPU, memory, disk, and network usage for specific pods or nodes
2. Identifying top-K resource-consuming pods by CPU, memory, disk, or network
3. Checking pod readiness and general health status within a namespace
4. Analyzing resource usage trends over time (e.g., last 1h, 1d, 1mo)
5. Comparing usage across different namespaces or time intervals
6. Generating CSV reports for selected pods and time ranges. The report will be returned as a downloadable link.
7. Responding in natural language while calling relevant functions to fetch live data
8. Format multi-item results using bullet points or line breaks for readability.

When a user asks a question, determine if it requires a tool call (e.g., to Prometheus). If so, call the appropriate tool and use the results to provide a concise, helpful, and actionable summary. Avoid guessing if data is unavailableâ€”inform the user clearly and suggest alternatives.
"""

MAX_TOOL_SUMMARY = 400        # å–®æ¢è¨Šæ¯ä¸Šé™
MAX_TOTAL_CHARS  = 15000      # æ•´åŒ… JSON ä¸Šé™ï¼ˆç´„ 6â€“7k tokensï¼‰

def _summarize(text: str, limit: int = MAX_TOOL_SUMMARY) -> str:
    """é•·åº¦>limit å°±è£åˆ‡ï¼Œé¿å…å¡çˆ† context"""
    return text if len(text) <= limit else text[:limit] + f"...(truncated {len(text)-limit} chars)"

def _shrink_until_ok(msgs: list[dict]) -> list[dict]:
    """
    1. å…ˆæŠŠ role=='tool' çš„ content åšæ‘˜è¦
    2. è‹¥ç¸½é•·åº¦ä»è¶…é MAX_TOTAL_CHARSï¼Œå¾€å‰ç æœ€èˆŠçš„ä¸€å¥
    """
    for m in msgs:
        if m["role"] == "tool":
            m["content"] = _summarize(m["content"])
    while len(json.dumps(msgs)) > MAX_TOTAL_CHARS:
        # ä¿ç•™æœ€å¾Œ 5 å¥ï¼Œå¾æœ€æ—©é–‹å§‹ç 
        for i, m in enumerate(msgs):
            if m["role"] != "system" and i < len(msgs) - 5:
                del msgs[i]
                break
    return msgs

MAX_HISTORY_LEN = 20   # ä¾éœ€è¦èª¿

def prune_history(hist: list[dict]) -> list[dict]:
    """åªä¿ç•™æœ€è¿‘ MAX_HISTORY_LEN å¥å°è©±"""
    if len(hist) > MAX_HISTORY_LEN:
        return hist[-MAX_HISTORY_LEN:]
    return hist

def chat_with_llm(user_message: str, history: list | None = None) -> Dict[str, Any]:
    """åŒæ­¥å‡½å¼ï¼Œä¸è¦ç”¨ await å‘¼å«"""
        # ---------- Filterv ---------- ä¸‹é¢é€™é‚Šæ˜¯é˜¿äº¨æŸ±è§£æ‰çš„RAGå•é¡Œ
#    if not is_supported(user_message):
#        return {
#            "assistant": (
#                "âš ï¸  I only answer Kubernetes pod / namespace monitoring "
#                "questions about CPU, Memory, Disk or Network in a valid "
#                "time range (e.g. 30m, 1h, 2d, 1mo). Please rephrase."
#            ),
#            "history": history or []
#        }
    # ---------- Retrieve ----------
    #rag_ctx = rag_retrieve(user_message, top_k=3)

    history = prune_history(history or [])
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
       # {"role": "system", "content": f"[RAG Knowledge]\n{rag_ctx}"},   # â† æ–°å¢
        *history,
        {"role": "user",   "content": user_message},
    ]
    messages.append({"role": "user", "content": user_message})

    # ç¬¬ä¸€æ¬¡å‘¼å«ï¼šLLM æ±ºå®šæ˜¯å¦å‘¼å«å·¥å…·
    from groq import BadRequestError
    try:
        resp = client.chat.completions.create(
            model       = MODEL,
            messages    = messages,
            tools       = TOOLS_DEF,
            tool_choice = "auto",
            max_tokens  = 800,
        )
    except BadRequestError as err:
        # Groq æœƒå› {"error":{...,"code":"tool_use_failed",...}}
        human = (
            "âš ï¸  I couldn't execute that request (invalid tool arguments). "
            "Try specifying: namespace, metric (cpu/memory), duration like 30m/2h/1d."
        )
        return {"assistant": human, "history": history or []}
    assistant_msg = resp.choices[0].message

    # å…ˆå–å‡º tool_calls
    tool_calls = getattr(assistant_msg, "tool_calls", None) or []
    messages.append({
        "role": "assistant",
        "content": assistant_msg.content,
        "tool_calls": tool_calls
    })

    # å¦‚æœæœ‰ tool_callsï¼Œå°±åŸ·è¡Œä¸¦ append çµæœ(é€™é‚Šè§£æ±ºé–‹æœƒå‡ºç¾çš„å•é¡Œï¼šCompare the top 3 CPU-heavy pods in the `default` namespace between now and 24 hours ago. What changed?)
    for tool_call in tool_calls:
        fn = FUNC_MAP.get(tool_call.function.name)
        if not fn:
            continue
        try:
            args = json.loads(tool_call.function.arguments)
        except json.JSONDecodeError as e:
            # LLM ç”¢ç”Ÿä¸åˆæ³• JSON â†’ å›æº«å’ŒéŒ¯èª¤ï¼ŒçµæŸæœ¬è¼ªå°è©±
            err_msg = (
                "âš ï¸ I generated malformed tool arguments, "
                "please rephrase your question (e.g. fix the time window)."
            )
            return {"assistant": err_msg, "history": history or []}
        result = fn(**args)
        messages.append({
            "role": "tool",
            "content": result,
            "tool_call_id": tool_call.id
        })

    # ç¬¬äºŒæ¬¡å‘¼å«ï¼šæ ¹æ“šå·¥å…·çµæœè¼¸å‡ºæœ€çµ‚å›ç­”
    if tool_calls:
        resp2 = client.chat.completions.create(
            model       = MODEL,
            messages    = messages,
            tools       = TOOLS_DEF,
            tool_choice = "none",
            max_tokens  = 800,
        )
        final_msg = resp2.choices[0].message
        messages.append({"role": "assistant", "content": final_msg.content})

    # è¿”å›çµ¦å‰ç«¯ï¼šå»é™¤ systemï¼Œä¸¦ç¢ºä¿ assistant å›æ‡‰ä¸ç‚º None
    front_history = [m for m in messages if m["role"] != "system"]
    last_msg = messages[-1]
    assistant_content = last_msg.get("content") or "[Error: No response generated from the assistant.]"
    
    return {"assistant": assistant_content, "history": front_history}

